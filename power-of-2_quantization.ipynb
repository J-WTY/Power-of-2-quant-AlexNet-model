{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BXKQkZ706MTZ"
      },
      "outputs": [],
      "source": [
        "# Modified from\n",
        "# https://github.com/pytorch/vision/blob/release/0.8.0/torchvision/models/resnet.py\n",
        "\n",
        "import torch\n",
        "from torch import Tensor\n",
        "import torch.nn as nn\n",
        "from torch.hub import load_state_dict_from_url\n",
        "from typing import Type, Any, Callable, Union, List, Optional\n",
        "import os\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "import time\n",
        "import copy\n",
        "import numpy as np\n",
        "import math\n",
        "from torch.autograd import Variable\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f8W16Z7hkP4Q"
      },
      "outputs": [],
      "source": [
        "def set_random_seeds(random_seed=0):\n",
        "\n",
        "    torch.manual_seed(random_seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    np.random.seed(random_seed)\n",
        "    random.seed(random_seed)\n",
        "\n",
        "def prepare_dataloader(num_workers=8, train_batch_size=128, eval_batch_size=256):\n",
        "\n",
        "    train_transform = transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.RandomCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "    ])\n",
        "\n",
        "    test_transform = transforms.Compose([\n",
        "        transforms.Resize(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "    ])\n",
        "\n",
        "    train_set = torchvision.datasets.CIFAR10(root=\"data\", train=True, download=True, transform=train_transform) \n",
        "    # We will use test set for validation and test in this project.\n",
        "    # Do not use test set for validation in practice!\n",
        "    test_set = torchvision.datasets.CIFAR10(root=\"data\", train=False, download=True, transform=test_transform)\n",
        "\n",
        "    train_sampler = torch.utils.data.RandomSampler(train_set)\n",
        "    test_sampler = torch.utils.data.SequentialSampler(test_set)\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        dataset=train_set, batch_size=train_batch_size,\n",
        "        sampler=train_sampler, num_workers=num_workers)\n",
        "\n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "        dataset=test_set, batch_size=eval_batch_size,\n",
        "        sampler=test_sampler, num_workers=num_workers)\n",
        "\n",
        "    return train_loader, test_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gQ7r8j9HkSYN"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, test_loader, device, criterion=None):\n",
        "\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "\n",
        "    running_loss = 0\n",
        "    running_corrects = 0\n",
        "\n",
        "    for inputs, labels in test_loader:\n",
        "\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "\n",
        "        if criterion is not None:\n",
        "            loss = criterion(outputs, labels).item()\n",
        "        else:\n",
        "            loss = 0\n",
        "\n",
        "        # statistics\n",
        "        running_loss += loss * inputs.size(0)\n",
        "        running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "    eval_loss = running_loss / len(test_loader.dataset)\n",
        "    eval_accuracy = running_corrects / len(test_loader.dataset)\n",
        "\n",
        "    return eval_loss, eval_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6IITs-WFkXG_"
      },
      "outputs": [],
      "source": [
        "def train_model(model, train_loader, test_loader, device):\n",
        "\n",
        "    # The training configurations were not carefully selected.\n",
        "    learning_rate = 1e-4\n",
        "    num_epochs = 7\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    model.to(device)\n",
        "\n",
        "    # It seems that SGD optimizer is better than Adam optimizer for ResNet18 training on CIFAR10.\n",
        "    optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=1e-5)\n",
        "    # optimizer = optim.Adam(model.parameters(), lr=learning_rate, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "        # Training\n",
        "        model.train()\n",
        "\n",
        "        running_loss = 0\n",
        "        running_corrects = 0\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward + backward + optimize\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # statistics\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        train_loss = running_loss / len(train_loader.dataset)\n",
        "        train_accuracy = running_corrects / len(train_loader.dataset)\n",
        "\n",
        "        # Evaluation\n",
        "        model.eval()\n",
        "        eval_loss, eval_accuracy = evaluate_model(model=model, test_loader=test_loader, device=device, criterion=criterion)\n",
        "\n",
        "        print(\"Epoch: {:02d} Train Loss: {:.3f} Train Acc: {:.3f} Eval Loss: {:.3f} Eval Acc: {:.3f}\".format(epoch, train_loss, train_accuracy, eval_loss, eval_accuracy))\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fYAz0oczkc5E"
      },
      "outputs": [],
      "source": [
        "def calibrate_model(model, loader, device=torch.device(\"cpu:0\")):\n",
        "\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    for inputs, labels in loader:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        _ = model(inputs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tOkbUESdkhCO"
      },
      "outputs": [],
      "source": [
        "def measure_inference_latency(model,\n",
        "                              device,\n",
        "                              input_size=(1, 3, 32, 32),\n",
        "                              num_samples=100,\n",
        "                              num_warmups=10):\n",
        "\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    x = torch.rand(size=input_size).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for _ in range(num_warmups):\n",
        "            _ = model(x)\n",
        "    torch.cuda.synchronize()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        start_time = time.time()\n",
        "        for _ in range(num_samples):\n",
        "            _ = model(x)\n",
        "            torch.cuda.synchronize()\n",
        "        end_time = time.time()\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_time_ave = elapsed_time / num_samples\n",
        "\n",
        "    return elapsed_time_ave"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I7QHx-otklE4"
      },
      "outputs": [],
      "source": [
        "def save_model(model, model_dir, model_filename):\n",
        "\n",
        "    if not os.path.exists(model_dir):\n",
        "        os.makedirs(model_dir)\n",
        "    model_filepath = os.path.join(model_dir, model_filename)\n",
        "    torch.save(model.state_dict(), model_filepath)\n",
        "\n",
        "def load_model(model, model_filepath, device):\n",
        "\n",
        "    model.load_state_dict(torch.load(model_filepath, map_location=device))\n",
        "\n",
        "    return model\n",
        "\n",
        "def save_torchscript_model(model, model_dir, model_filename):\n",
        "\n",
        "    if not os.path.exists(model_dir):\n",
        "        os.makedirs(model_dir)\n",
        "    model_filepath = os.path.join(model_dir, model_filename)\n",
        "    torch.jit.save(torch.jit.script(model), model_filepath)\n",
        "\n",
        "def load_torchscript_model(model_filepath, device):\n",
        "\n",
        "    model = torch.jit.load(model_filepath, map_location=device)\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lsKrsHoEklfE"
      },
      "outputs": [],
      "source": [
        "def create_model(num_classes=10):\n",
        "\n",
        "    # The number of channels in ResNet18 is divisible by 8.\n",
        "    # This is required for fast GEMM integer matrix multiplication.\n",
        "    # model = torchvision.models.resnet18(pretrained=False)\n",
        "    model = torch.hub.load('pytorch/vision:v0.10.0', 'alexnet', pretrained=True)\n",
        "    \n",
        "    model.classifier[4] = nn.Linear(4096,1024)\n",
        "\n",
        "    #Updating the third and the last classifier that is the output layer of the network. Make sure to have 10 output nodes if we are going to get 10 class labels through our model.\n",
        "    model.classifier[6] = nn.Linear(1024,10)\n",
        "    # We would use the pretrained ResNet18 as a feature extractor.\n",
        "    # for param in model.parameters():\n",
        "    #     param.requires_grad = False\n",
        "    \n",
        "    # Modify the last FC layer\n",
        "    # num_features = model.fc.in_features\n",
        "    # model.fc = nn.Linear(num_features, 10)\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4j4rhIeflMcH"
      },
      "outputs": [],
      "source": [
        "class QuantizedAlexNet(nn.Module):\n",
        "    def __init__(self, model_fp32):\n",
        "        super(QuantizedAlexNet, self).__init__()\n",
        "        # QuantStub converts tensors from floating point to quantized.\n",
        "        # This will only be used for inputs.\n",
        "        self.quant = torch.quantization.QuantStub()\n",
        "        # DeQuantStub converts tensors from quantized to floating point.\n",
        "        # This will only be used for outputs.\n",
        "        self.dequant = torch.quantization.DeQuantStub()\n",
        "        # FP32 model\n",
        "        self.model_fp32 = model_fp32\n",
        "\n",
        "    def forward(self, x):\n",
        "        # manually specify where tensors will be converted from floating\n",
        "        # point to quantized in the quantized model\n",
        "        x = self.quant(x)\n",
        "        x = self.model_fp32(x)\n",
        "        # manually specify where tensors will be converted from quantized\n",
        "        # to floating point in the quantized model\n",
        "        x = self.dequant(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P6txr-NwlOIt"
      },
      "outputs": [],
      "source": [
        "def model_equivalence(model_1, model_2, device, rtol=1e-05, atol=1e-08, num_tests=100, input_size=(1,3,224,224)):\n",
        "\n",
        "    model_1.to(device)\n",
        "    model_2.to(device)\n",
        "\n",
        "    for _ in range(num_tests):\n",
        "        x = torch.rand(size=input_size).to(device)\n",
        "        y1 = model_1(x).detach().cpu().numpy()\n",
        "        y2 = model_2(x).detach().cpu().numpy()\n",
        "        if np.allclose(a=y1, b=y2, rtol=rtol, atol=atol, equal_nan=False) == False:\n",
        "            print(\"Model equivalence test sample failed: \")\n",
        "            print(y1)\n",
        "            print(y2)\n",
        "            return False\n",
        "\n",
        "    return True\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 354,
          "referenced_widgets": [
            "76c6d576d5a84be381c3b179fd99de11",
            "0573fdf62f4943199f57366d4e25a45b",
            "630761d8dd864a62bec9edafed8c1011",
            "541d1f9d45ab49b3b87c8f8708219a0c",
            "ecbb0ab2a55c492793ab5e49b7d00ec6",
            "8d82e751887849d78c12b2e759e099ad",
            "f5bc2ccdf2cc49209d52938b36a0b715",
            "afe1bc196c3f4ac8909190f214364ec0",
            "bf67bd2881394fedb2c7ac35cc511721",
            "425f2e2d2994474aa70cc76f8e5eb31a",
            "0c3accfdf17d42258b43a8c9fa5e1000",
            "eb0404bc0bc648128a6b1872406bbaa3",
            "a68390af66b741b6977d041a4e719bcb",
            "3afae834def14906a3ed066c25c9d9d0",
            "e27fb8619fe04d16b25d24ed538c1025",
            "b8a19e50b337436680a5624929ddaa06",
            "ae221386d45149d9aacfe3d0a988df22",
            "6b599b8e63604a3cace5cb61c75b3fd2",
            "f6066fd862284891b0322b86d84c752a",
            "45aab8d194354c1e9c7f6963123e999d",
            "cde88202e16f45bea369c56674055be5",
            "0093f34775f24360b1701a7c3ec02b53"
          ]
        },
        "id": "k6RdQj45let-",
        "outputId": "bf372784-8fd9-45e5-b477-6e79383fa0cf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://github.com/pytorch/vision/zipball/v0.10.0\" to /root/.cache/torch/hub/v0.10.0.zip\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /root/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "76c6d576d5a84be381c3b179fd99de11",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0.00/233M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eb0404bc0bc648128a6b1872406bbaa3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data/cifar-10-python.tar.gz to data\n",
            "Files already downloaded and verified\n",
            "Epoch: 00 Train Loss: 1.511 Train Acc: 0.466 Eval Loss: 0.848 Eval Acc: 0.711\n",
            "Epoch: 01 Train Loss: 0.853 Train Acc: 0.699 Eval Loss: 0.657 Eval Acc: 0.777\n",
            "Epoch: 02 Train Loss: 0.724 Train Acc: 0.747 Eval Loss: 0.597 Eval Acc: 0.796\n",
            "Epoch: 03 Train Loss: 0.659 Train Acc: 0.770 Eval Loss: 0.543 Eval Acc: 0.815\n",
            "Epoch: 04 Train Loss: 0.617 Train Acc: 0.786 Eval Loss: 0.527 Eval Acc: 0.821\n",
            "Epoch: 05 Train Loss: 0.582 Train Acc: 0.798 Eval Loss: 0.493 Eval Acc: 0.833\n",
            "Epoch: 06 Train Loss: 0.554 Train Acc: 0.807 Eval Loss: 0.483 Eval Acc: 0.837\n"
          ]
        }
      ],
      "source": [
        "random_seed = 0\n",
        "num_classes = 10\n",
        "cuda_device = torch.device(\"cuda:0\")\n",
        "cpu_device = torch.device(\"cpu:0\")\n",
        "\n",
        "model_dir = \"saved_models\"\n",
        "model_filename = \"alexnet_cifar10.pt\"\n",
        "quantized_model_filename = \"alexnet_quantized_cifar10.pt\"\n",
        "model_filepath = os.path.join(model_dir, model_filename)\n",
        "quantized_model_filepath = os.path.join(model_dir, quantized_model_filename)\n",
        "\n",
        "set_random_seeds(random_seed=random_seed)\n",
        "\n",
        "# Create an untrained model.\n",
        "model = create_model(num_classes=num_classes)\n",
        "\n",
        "train_loader, test_loader = prepare_dataloader(num_workers=2, train_batch_size=128, eval_batch_size=256)\n",
        "\n",
        "# Train model.\n",
        "model = train_model(model=model, train_loader=train_loader, test_loader=test_loader, device=cuda_device)\n",
        "#model = load_model(model=model, model_filepath=\"alexnet_cifar10.pt\", device=cuda_device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "vF4Ls8RnqNBZ",
        "outputId": "f31e2dfd-f15a-4700-a6f4-02a385afb68b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "False\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "#import os\n",
        "isFile = os.path.isfile(\"readme.txt\")\n",
        "print(isFile)\n",
        "with open(\"readme.txt\",\"w\") as f:\n",
        "    f.close()\n",
        "isFile = os.path.isfile(\"readme.txt\")\n",
        "print(isFile)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_-vDlM5G6udO",
        "outputId": "2bb78060-1548-4290-d919-2a3d4c796448"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AlexNet(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): ReLU(inplace=True)\n",
            "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
            "  (classifier): Sequential(\n",
            "    (0): Dropout(p=0.5, inplace=False)\n",
            "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Dropout(p=0.5, inplace=False)\n",
            "    (4): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): Linear(in_features=1024, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "isFile = False\n",
        "features = []\n",
        "class AlexNet(nn.Module):\n",
        "    def __init__(self, num_classes: int = 10, dropout: float = 0.5) -> None:\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "        )\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(p=dropout),\n",
        "            nn.Linear(256 * 6 * 6, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=dropout),\n",
        "            nn.Linear(4096, 1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(1024, num_classes),\n",
        "        )\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        if(isFile):\n",
        "            feature1 = x.reshape(x.shape[0], -1)\n",
        "            \"\"\"\n",
        "            with open('readme.txt', 'a') as f:\n",
        "                for i in range(x.size(dim=0)):\n",
        "                    for j in range(x.size(dim=1)):\n",
        "                        for k in range(x.size(dim=2)):\n",
        "                            for l in range(x.size(dim=3)):\n",
        "                                f.write('{}\\t'.format(x[i][j][k][l]))\n",
        "                f.write(\"\\n\\n\")\n",
        "            \"\"\"\n",
        "            x = self.features[0](x)\n",
        "            \"\"\"\n",
        "            with open('readme.txt', 'a') as f:\n",
        "                for i in range(x.size(dim=0)):\n",
        "                    for j in range(x.size(dim=1)):\n",
        "                        for k in range(x.size(dim=2)):\n",
        "                            for l in range(x.size(dim=3)):\n",
        "                                f.write('{}\\t'.format(x[i][j][k][l]))\n",
        "                f.write(\"\\n\\n\")\n",
        "            \"\"\"\n",
        "            feature2 = x.reshape(x.shape[0], -1)\n",
        "            x = self.features[1](x)\n",
        "            x = self.features[2](x)\n",
        "            \"\"\"\n",
        "            with open('readme.txt', 'a') as f:\n",
        "                for i in range(x.size(dim=0)):\n",
        "                    for j in range(x.size(dim=1)):\n",
        "                        for k in range(x.size(dim=2)):\n",
        "                            for l in range(x.size(dim=3)):\n",
        "                                f.write('{}\\t'.format(x[i][j][k][l]))\n",
        "                f.write(\"\\n\\n\")\n",
        "            \"\"\"\n",
        "            feature3 = x.reshape(x.shape[0], -1)\n",
        "            x = self.features[3](x)\n",
        "            \"\"\"\n",
        "            with open('readme.txt', 'a') as f:\n",
        "                for i in range(x.size(dim=0)):\n",
        "                    for j in range(x.size(dim=1)):\n",
        "                        for k in range(x.size(dim=2)):\n",
        "                            for l in range(x.size(dim=3)):\n",
        "                                f.write('{}\\t'.format(x[i][j][k][l]))\n",
        "                f.write(\"\\n\\n\")\n",
        "            \"\"\"\n",
        "            feature4 = x.reshape(x.shape[0], -1)\n",
        "            x = self.features[4](x)\n",
        "            x = self.features[5](x)\n",
        "            \"\"\"\n",
        "            with open('readme.txt', 'a') as f:\n",
        "                for i in range(x.size(dim=0)):\n",
        "                    for j in range(x.size(dim=1)):\n",
        "                        for k in range(x.size(dim=2)):\n",
        "                            for l in range(x.size(dim=3)):\n",
        "                                f.write('{}\\t'.format(x[i][j][k][l]))\n",
        "                f.write(\"\\n\\n\")\n",
        "            \"\"\"\n",
        "            feature5 = x.reshape(x.shape[0], -1)\n",
        "            x = self.features[6](x)\n",
        "            \"\"\"\n",
        "            with open('readme.txt', 'a') as f:\n",
        "                for i in range(x.size(dim=0)):\n",
        "                    for j in range(x.size(dim=1)):\n",
        "                        for k in range(x.size(dim=2)):\n",
        "                            for l in range(x.size(dim=3)):\n",
        "                                f.write('{}\\t'.format(x[i][j][k][l]))\n",
        "                f.write(\"\\n\\n\")\n",
        "            \"\"\"\n",
        "            feature6 = x.reshape(x.shape[0], -1)\n",
        "            x = self.features[7](x)\n",
        "            \"\"\"\n",
        "            with open('readme.txt', 'a') as f:\n",
        "                for i in range(x.size(dim=0)):\n",
        "                    for j in range(x.size(dim=1)):\n",
        "                        for k in range(x.size(dim=2)):\n",
        "                            for l in range(x.size(dim=3)):\n",
        "                                f.write('{}\\t'.format(x[i][j][k][l]))\n",
        "                f.write(\"\\n\\n\")\n",
        "            \"\"\"\n",
        "            feature7 = x.reshape(x.shape[0], -1)\n",
        "            x = self.features[8](x)\n",
        "            \"\"\"\n",
        "            with open('readme.txt', 'a') as f:\n",
        "                for i in range(x.size(dim=0)):\n",
        "                    for j in range(x.size(dim=1)):\n",
        "                        for k in range(x.size(dim=2)):\n",
        "                            for l in range(x.size(dim=3)):\n",
        "                                f.write('{}\\t'.format(x[i][j][k][l]))\n",
        "                f.write(\"\\n\\n\")\n",
        "            \"\"\"\n",
        "            feature8 = x.reshape(x.shape[0], -1)\n",
        "            x = self.features[9](x)\n",
        "            \"\"\"\n",
        "            with open('readme.txt', 'a') as f:\n",
        "                for i in range(x.size(dim=0)):\n",
        "                    for j in range(x.size(dim=1)):\n",
        "                        for k in range(x.size(dim=2)):\n",
        "                            for l in range(x.size(dim=3)):\n",
        "                                f.write('{}\\t'.format(x[i][j][k][l]))\n",
        "                f.write(\"\\n\\n\")\n",
        "            \"\"\"\n",
        "            feature9 = x.reshape(x.shape[0], -1)\n",
        "            x = self.features[10](x)\n",
        "\n",
        "            \"\"\"with open('readme.txt', 'a') as f:\n",
        "                for i in range(x.size(dim=0)):\n",
        "                    for j in range(x.size(dim=1)):\n",
        "                        for k in range(x.size(dim=2)):\n",
        "                            for l in range(x.size(dim=3)):\n",
        "                                f.write('{}\\t'.format(x[i][j][k][l]))\n",
        "                f.write(\"\\n\\n\")\n",
        "            \"\"\"\n",
        "            feature10 = x.reshape(x.shape[0], -1)\n",
        "            x = self.features[11](x)\n",
        "            x = self.features[12](x)      \n",
        "            x = self.avgpool(x)\n",
        "            x = torch.flatten(x, 1)\n",
        "            x = self.classifier[0](x)\n",
        "            x = self.classifier[1](x)\n",
        "            x = self.classifier[2](x)\n",
        "            x = self.classifier[3](x)\n",
        "            x = self.classifier[4](x)\n",
        "            x = self.classifier[5](x)\n",
        "            x = self.classifier[6](x)\n",
        "            #feature = torch.cat((feature1,feature2,feature3,feature4,feature5,feature6,feature7,feature8, feature9, feature10),0)\n",
        "            print(feature2)\n",
        "            feature = []\n",
        "            feature.append(feature1)\n",
        "            feature.append(feature2)\n",
        "            feature.append(feature3)\n",
        "            feature.append(feature4)\n",
        "            feature.append(feature5)\n",
        "            feature.append(feature6)\n",
        "            feature.append(feature7)\n",
        "            feature.append(feature8)\n",
        "            feature.append(feature9)\n",
        "            feature.append(feature10)\n",
        "            for i in range(10):\n",
        "                features.append(feature[i])\n",
        "            return x\n",
        "        else:\n",
        "            x = self.features[0](x)\n",
        "            x = self.features[1](x)\n",
        "            x = self.features[2](x)\n",
        "            x = self.features[3](x)\n",
        "            x = self.features[4](x)\n",
        "            x = self.features[5](x)\n",
        "            x = self.features[6](x)\n",
        "            x = self.features[7](x)\n",
        "            x = self.features[8](x)\n",
        "            x = self.features[9](x)\n",
        "            x = self.features[10](x)\n",
        "            x = self.features[11](x)\n",
        "            x = self.features[12](x)      \n",
        "            x = self.avgpool(x)\n",
        "            x = torch.flatten(x, 1)\n",
        "            x = self.classifier[0](x)\n",
        "            x = self.classifier[1](x)\n",
        "            x = self.classifier[2](x)\n",
        "            x = self.classifier[3](x)\n",
        "            x = self.classifier[4](x)\n",
        "            x = self.classifier[5](x)\n",
        "            x = self.classifier[6](x)\n",
        "            return x\n",
        "model2 = AlexNet()\n",
        "print(model2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "zREU3GtQMFTx"
      },
      "outputs": [],
      "source": [
        "model2.load_state_dict(model.state_dict())\n",
        "_, fp32_eval_accuracy = evaluate_model(model=model2, test_loader=test_loader, device=cpu_device, criterion=None)\n",
        "print(\"FP32 evaluation accuracy: {:.3f}\".format(fp32_eval_accuracy))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ZHUY4BcurJO6"
      },
      "outputs": [],
      "source": [
        "isFile = True\n",
        "\n",
        "\"\"\"\n",
        "with open(\"readme.txt\", \"w\") as f:\n",
        "  f.write(\"\")\n",
        "  f.close()\n",
        "\"\"\"\n",
        "imsize = 224\n",
        "loader = transforms.Compose([transforms.Resize(imsize), transforms.ToTensor()])\n",
        "\n",
        "\n",
        "def image_loader(image_name):\n",
        "    \"\"\"load image, returns cuda tensor\"\"\"\n",
        "    image = Image.open(image_name)\n",
        "    image = loader(image).float()\n",
        "    image = Variable(image, requires_grad=True)\n",
        "    image = image.unsqueeze(0)  #this is for VGG, may not be needed for ResNet\n",
        "    return image  #assumes that you're using GPU\n",
        "\n",
        "image = image_loader(\"images.jpg\")\n",
        "\"\"\"\n",
        "print(image)\n",
        "with open(\"readme.txt\", \"a\") as f:\n",
        "  f.write('{} '.format(image[0][0][0][0]))\"\"\"\n",
        "out, feature = model2(image)\n",
        "isFile = False\n",
        "print(out)\n",
        "print(feature[9])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5JdMt-ruyRBL"
      },
      "outputs": [],
      "source": [
        "with open(\"float32_input&output.txt\", \"w\") as f:\n",
        "    for i in range(10):\n",
        "        f.write(\"{}\\n\".format(i+1))\n",
        "        f.write(\"{}\".format(feature[i]))\n",
        "        f.write(\"\\n\")\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "NZEPPc5g0Mpp"
      },
      "outputs": [],
      "source": [
        "print(image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9BHMRLp6KhWm"
      },
      "outputs": [],
      "source": [
        "for param_tensor in model.state_dict():\n",
        "    print(param_tensor, \"\\n\", model.state_dict()[param_tensor])\n",
        "    model2.state_dict()[param_tensor] = model.state_dict()[param_tensor]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9dmjumzWLM-C"
      },
      "outputs": [],
      "source": [
        "for param_tensor in model2.state_dict():\n",
        "    print(param_tensor, \"\\n\", model2.state_dict()[param_tensor])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "RsgumBlFUtxh"
      },
      "outputs": [],
      "source": [
        "# Save model.\n",
        "save_model(model=model2, model_dir=model_dir, model_filename=model_filename)\n",
        "# Load a pretrained model.\n",
        "model2 = load_model(model=model2, model_filepath=model_filepath, device=cuda_device)\n",
        "# Move the model to CPU since static quantization does not support CUDA currently.\n",
        "model2.to(cpu_device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1y1LXMO3UydC"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Make a copy of the model for layer fusion\n",
        "fused_model = copy.deepcopy(model2)\n",
        "\n",
        "model2.eval()\n",
        "# The model has to be switched to evaluation mode before any layer fusion.\n",
        "# Otherwise the quantization will not work correctly.\n",
        "fused_model.eval()\n",
        "\n",
        "# Fuse the model in place rather manually.\n",
        "#fused_model = torch.quantization.fuse_modules(fused_model, [[\"relu\"]], inplace=True)\n",
        "for module_name, module in fused_model.named_children():\n",
        "    if \"layer\" in module_name:\n",
        "        for basic_block_name, basic_block in module.named_children():\n",
        "            torch.quantization.fuse_modules(basic_block, [[\"conv1\", \"bn1\", \"relu1\"], [\"conv2\", \"bn2\"]], inplace=True)\n",
        "            for sub_block_name, sub_block in basic_block.named_children():\n",
        "                if sub_block_name == \"downsample\":\n",
        "                    torch.quantization.fuse_modules(sub_block, [[\"0\", \"1\"]], inplace=True)\n",
        "\n",
        "# Print FP32 model.\n",
        "print(model2)\n",
        "# Print fused model.\n",
        "print(fused_model)\n",
        "\n",
        "# Model and fused model should be equivalent.\n",
        "assert model_equivalence(model_1=model2, model_2=fused_model, device=cpu_device, rtol=1e-03, atol=1e-06, num_tests=100, input_size=(1,3,224,224)), \"Fused model is not equivalent to the original model!\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Rh3ZGAcFXQCW"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Prepare the model for static quantization. This inserts observers in\n",
        "# the model that will observe activation tensors during calibration.\n",
        "quantized_model = QuantizedAlexNet(model_fp32=fused_model)\n",
        "# Using un-fused model will fail.\n",
        "# Because there is no quantized layer implementation for a single batch normalization layer.\n",
        "# quantized_model = QuantizedResNet18(model_fp32=model)\n",
        "# Select quantization schemes from \n",
        "# https://pytorch.org/docs/stable/quantization-support.html\n",
        "quantization_config = torch.quantization.get_default_qconfig(\"fbgemm\")\n",
        "# Custom quantization configurations\n",
        "# quantization_config = torch.quantization.default_qconfig\n",
        "\n",
        "quantized_model.qconfig = quantization_config\n",
        "# Print quantization configurations\n",
        "#print(quantized_model.qconfig)\n",
        "print(quantized_model)\n",
        "\n",
        "torch.quantization.prepare(quantized_model, inplace=True)\n",
        "\n",
        "\n",
        "# Use training data for calibration.\n",
        "calibrate_model(model=quantized_model, loader=train_loader, device=cpu_device)\n",
        "\n",
        "quantized_model = torch.quantization.convert(quantized_model, inplace=True)\n",
        "\n",
        "# Using high-level static quantization wrapper\n",
        "# The above steps, including torch.quantization.prepare, calibrate_model, and torch.quantization.convert, are also equivalent to\n",
        "# quantized_model = torch.quantization.quantize(model=quantized_model, run_fn=calibrate_model, run_args=[train_loader], mapping=None, inplace=False)\n",
        "\n",
        "quantized_model.eval()\n",
        "\n",
        "# Print quantized model.\n",
        "print(quantized_model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "M_DLvo24It8U"
      },
      "outputs": [],
      "source": [
        "quantized_model.model_fp32.features[0].scale = math.pow(2, round(math.log(quantized_model.model_fp32.features[0].scale,2), 0))\n",
        "print(quantized_model.model_fp32.features[0].scale)\n",
        "\n",
        "quantized_model.model_fp32.features[3].scale = math.pow(2, round(math.log(quantized_model.model_fp32.features[3].scale,2), 0))\n",
        "print(quantized_model.model_fp32.features[3].scale)\n",
        "\n",
        "quantized_model.model_fp32.features[6].scale = math.pow(2, round(math.log(quantized_model.model_fp32.features[6].scale,2), 0))\n",
        "print(quantized_model.model_fp32.features[6].scale)\n",
        "\n",
        "quantized_model.model_fp32.features[8].scale = math.pow(2, round(math.log(quantized_model.model_fp32.features[8].scale,2), 0))\n",
        "print(quantized_model.model_fp32.features[8].scale)\n",
        "\n",
        "quantized_model.model_fp32.features[10].scale = math.pow(2, round(math.log(quantized_model.model_fp32.features[10].scale,2), 0))\n",
        "print(quantized_model.model_fp32.features[10].scale)\n",
        "\n",
        "quantized_model.model_fp32.classifier[1].scale = math.pow(2, round(math.log(quantized_model.model_fp32.classifier[1].scale,2), 0))\n",
        "print(quantized_model.model_fp32.classifier[1].scale)\n",
        "\n",
        "quantized_model.model_fp32.classifier[4].scale = math.pow(2, round(math.log(quantized_model.model_fp32.classifier[4].scale,2), 0))\n",
        "print(quantized_model.model_fp32.classifier[4].scale)\n",
        "\n",
        "quantized_model.model_fp32.classifier[6].scale = math.pow(2, round(math.log(quantized_model.model_fp32.classifier[6].scale,2), 0))\n",
        "print(quantized_model.model_fp32.classifier[6].scale)\n",
        "\n",
        "quantized_model.quant.scale[0]=math.pow(2, round( math.log(quantized_model.quant.scale[0],2),0))\n",
        "print(quantized_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WyO_vecelwQS"
      },
      "outputs": [],
      "source": [
        "# Save quantized model.\n",
        "save_torchscript_model(model=quantized_model, model_dir=model_dir, model_filename=quantized_model_filename)\n",
        "\n",
        "# Load quantized model.\n",
        "quantized_jit_model = load_torchscript_model(model_filepath=quantized_model_filepath, device=cpu_device)\n",
        "quantized_jit_model "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "v9UpcakkmBZm"
      },
      "outputs": [],
      "source": [
        "_, fp32_eval_accuracy = evaluate_model(model=model2, test_loader=test_loader, device=cpu_device, criterion=None)\n",
        "_, int16_eval_accuracy = evaluate_model(model=quantized_model, test_loader=test_loader, device=cpu_device, criterion=None)\n",
        "\n",
        "# Skip this assertion since the values might deviate a lot.\n",
        "# assert model_equivalence(model_1=model, model_2=quantized_jit_model, device=cpu_device, rtol=1e-01, atol=1e-02, num_tests=100, input_size=(1,3,32,32)), \"Quantized model deviates from the original model too much!\"\n",
        "\n",
        "print(\"FP32 evaluation accuracy: {:.3f}\".format(fp32_eval_accuracy))\n",
        "print(\"INT8 evaluation accuracy: {:.3f}\".format(int16_eval_accuracy))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6GuqyupnK3N1"
      },
      "outputs": [],
      "source": [
        "from torch.autograd import Variable\n",
        "from PIL import Image\n",
        "inference = True\n",
        "imsize = 224\n",
        "loader = transforms.Compose([transforms.Resize(imsize), transforms.ToTensor()])\n",
        "\n",
        "\n",
        "def image_loader(image_name):\n",
        "    \"\"\"load image, returns cuda tensor\"\"\"\n",
        "    image = Image.open(image_name)\n",
        "    image = loader(image).float()\n",
        "    image = Variable(image, requires_grad=True)\n",
        "    image = image.unsqueeze(0)\n",
        "    return image\n",
        "\n",
        "image = image_loader(\"images.jpg\")\n",
        "\n",
        "output= quantized_model(image)\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4W82icq1MJao"
      },
      "outputs": [],
      "source": [
        "torch.set_printoptions(threshold=10_000000)\n",
        "np.set_printoptions(threshold=10_000000)\n",
        "max = -999999\n",
        "min = 999999\n",
        "\n",
        "with open(\"quantized_input&output.txt\", \"w\") as f:\n",
        "    for index in range(10):\n",
        "        f.write(\"{}\\n\".format(features[index][0].size(dim=0)))\n",
        "        f.write(\"{}\\n\".format(features[index][0]))\n",
        "        for i in range(features[index][0].size(dim=0)):\n",
        "            if(features[index][0][i] > max):\n",
        "                max = features[index][0][i]\n",
        "            if(features[index][0][i] < min):\n",
        "                min = features[index][0][i]\n",
        "\n",
        "print(max)\n",
        "print(min)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "DdW9fE0m1FJ1"
      },
      "outputs": [],
      "source": [
        "torch.set_printoptions(threshold=10_00000)\n",
        "np.set_printoptions(threshold=10_00000)\n",
        "max = -99999\n",
        "min = 99999\n",
        "for index in range(10):\n",
        "    for i in range(features[index][0].size(dim=0)):\n",
        "        if(features[index][0][i] > max):\n",
        "          max = features[index][0][i]\n",
        "        if(features[index][0][i] < min):\n",
        "          min = features[index][0][i]\n",
        "\n",
        "print(max)\n",
        "print(min)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "IbiZxlsE6Mxq"
      },
      "outputs": [],
      "source": [
        "fp32_cpu_inference_latency = measure_inference_latency(model=model, device=cpu_device, input_size=(1,3,224,224), num_samples=100)\n",
        "int16_cpu_inference_latency = measure_inference_latency(model=quantized_model, device=cpu_device, input_size=(1,3,224,224), num_samples=100)\n",
        "int16_jit_cpu_inference_latency = measure_inference_latency(model=quantized_jit_model, device=cpu_device, input_size=(1,3,224,224), num_samples=100)\n",
        "fp32_gpu_inference_latency = measure_inference_latency(model=model, device=cuda_device, input_size=(1,3,224,224), num_samples=100)\n",
        "\n",
        "print(\"FP32 CPU Inference Latency: {:.2f} ms / sample\".format(fp32_cpu_inference_latency * 1000))\n",
        "#print(\"FP32 CUDA Inference Latency: {:.2f} ms / sample\".format(fp32_gpu_inference_latency * 1000))\n",
        "print(\"INT16 CPU Inference Latency: {:.2f} ms / sample\".format(int16_cpu_inference_latency * 1000))\n",
        "#print(\"INT16 JIT CPU Inference Latency: {:.2f} ms / sample\".format(int16_jit_cpu_inference_latency * 1000))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "c2RPnCYVFEvb"
      },
      "outputs": [],
      "source": [
        "with open(\"quantized_weight.txt\", \"w\") as f:\n",
        "  for weight in quantized_model.state_dict():\n",
        "    np.set_printoptions(threshold=10_0000)\n",
        "    f.write(weight)\n",
        "    f.write('\\n')\n",
        "    f.write(\"{}\".format(quantized_model.state_dict()[weight]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "RlgNlceLaQ1F"
      },
      "outputs": [],
      "source": [
        "with open(\"quantized_weight.txt\", \"w\") as f:\n",
        "  for weight in quantized_model.state_dict():\n",
        "      np.set_printoptions(suppress=True)\n",
        "      torch.set_printoptions(threshold=10_000000)\n",
        "      if(type(quantized_model.state_dict()[weight]) == torch.Tensor):\n",
        "          f.write(\"{}\\n\".format(quantized_model.state_dict()[weight].size()))\n",
        "          f.write(\"{}\".format(quantized_model.state_dict()[weight]))\n",
        "          f.write(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "W8hYQQJE6QCU"
      },
      "outputs": [],
      "source": [
        "with open(\"float_weight.txt\", \"w\") as f:\n",
        "    for param_tensor in model2.state_dict():\n",
        "        f.write(\"{}\\n\".format(param_tensor))\n",
        "        f.write(\"{}\".format(model2.state_dict()[param_tensor].size()))\n",
        "        f.write(\"{}\\n\".format(model2.state_dict()[param_tensor]))\n",
        "        #print(param_tensor, \"\\n\", model2.state_dict()[param_tensor])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "dQ9zerNtbPea"
      },
      "outputs": [],
      "source": [
        "for param in model2.parameters():\n",
        "    #torch.set_printoptions(threshold=10_0000)\n",
        "    print(param.data.size())\n",
        "    print(param.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "PaqJzJeOZ-SJ"
      },
      "outputs": [],
      "source": [
        "\"\"\"quantization_config = torch.quantization.QConfig(\n",
        "    activation=torch.quantization.MinMaxObserver.with_args(\n",
        "        dtype=torch.quint8,\n",
        "        qscheme=torch.per_tensor_symmetric,\n",
        "    ), \n",
        "    weight=torch.quantization.MinMaxObserver.with_args(\n",
        "        dtype=torch.qint8, \n",
        "        qscheme=torch.per_tensor_symmetric,\n",
        "    )\n",
        ")\n",
        "FP32 evaluation accuracy: 0.854\n",
        "INT8 evaluation accuracy: 0.814\n",
        "\"\"\"\n",
        "\"\"\"\n",
        "quantization_config = torch.quantization.get_default_qconfig(\"fbgemm\")\n",
        "FP32 evaluation accuracy: 0.850\n",
        "INT8 evaluation accuracy: 0.848\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "hobBYj2z7BIE"
      },
      "outputs": [],
      "source": [
        "for param_tensor in model2.state_dict():\n",
        "    print(param_tensor, \"\\n\", model2.state_dict()[param_tensor])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0TqncUlAkAfT"
      },
      "outputs": [],
      "source": [
        "for param_tensor in fused_model.state_dict():\n",
        "    print(param_tensor, \"\\n\", fused_model.state_dict()[param_tensor])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "I5552BjwUS0D"
      },
      "outputs": [],
      "source": [
        "quantized_model.model_fp32.features[0].scale = 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "UckIStYXhKGs"
      },
      "outputs": [],
      "source": [
        "quantized_model.model_fp32.features[0].scale = 0.25\n",
        "for param_tensor in quantized_model.state_dict():\n",
        "    print(param_tensor, \"\\n\", quantized_model.state_dict()[param_tensor])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0093f34775f24360b1701a7c3ec02b53": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0573fdf62f4943199f57366d4e25a45b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d82e751887849d78c12b2e759e099ad",
            "placeholder": "",
            "style": "IPY_MODEL_f5bc2ccdf2cc49209d52938b36a0b715",
            "value": "100%"
          }
        },
        "0c3accfdf17d42258b43a8c9fa5e1000": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3afae834def14906a3ed066c25c9d9d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6066fd862284891b0322b86d84c752a",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_45aab8d194354c1e9c7f6963123e999d",
            "value": 170498071
          }
        },
        "425f2e2d2994474aa70cc76f8e5eb31a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45aab8d194354c1e9c7f6963123e999d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "541d1f9d45ab49b3b87c8f8708219a0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_425f2e2d2994474aa70cc76f8e5eb31a",
            "placeholder": "",
            "style": "IPY_MODEL_0c3accfdf17d42258b43a8c9fa5e1000",
            "value": " 233M/233M [00:03&lt;00:00, 113MB/s]"
          }
        },
        "630761d8dd864a62bec9edafed8c1011": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_afe1bc196c3f4ac8909190f214364ec0",
            "max": 244408911,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bf67bd2881394fedb2c7ac35cc511721",
            "value": 244408911
          }
        },
        "6b599b8e63604a3cace5cb61c75b3fd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "76c6d576d5a84be381c3b179fd99de11": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0573fdf62f4943199f57366d4e25a45b",
              "IPY_MODEL_630761d8dd864a62bec9edafed8c1011",
              "IPY_MODEL_541d1f9d45ab49b3b87c8f8708219a0c"
            ],
            "layout": "IPY_MODEL_ecbb0ab2a55c492793ab5e49b7d00ec6"
          }
        },
        "8d82e751887849d78c12b2e759e099ad": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a68390af66b741b6977d041a4e719bcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae221386d45149d9aacfe3d0a988df22",
            "placeholder": "",
            "style": "IPY_MODEL_6b599b8e63604a3cace5cb61c75b3fd2",
            "value": "100%"
          }
        },
        "ae221386d45149d9aacfe3d0a988df22": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afe1bc196c3f4ac8909190f214364ec0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8a19e50b337436680a5624929ddaa06": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf67bd2881394fedb2c7ac35cc511721": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cde88202e16f45bea369c56674055be5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e27fb8619fe04d16b25d24ed538c1025": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cde88202e16f45bea369c56674055be5",
            "placeholder": "",
            "style": "IPY_MODEL_0093f34775f24360b1701a7c3ec02b53",
            "value": " 170498071/170498071 [00:04&lt;00:00, 53537172.01it/s]"
          }
        },
        "eb0404bc0bc648128a6b1872406bbaa3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a68390af66b741b6977d041a4e719bcb",
              "IPY_MODEL_3afae834def14906a3ed066c25c9d9d0",
              "IPY_MODEL_e27fb8619fe04d16b25d24ed538c1025"
            ],
            "layout": "IPY_MODEL_b8a19e50b337436680a5624929ddaa06"
          }
        },
        "ecbb0ab2a55c492793ab5e49b7d00ec6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5bc2ccdf2cc49209d52938b36a0b715": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f6066fd862284891b0322b86d84c752a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}